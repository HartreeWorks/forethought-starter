```json
[
  {
    "id": "total-utilitarianism",
    "name": "Total Utilitarianism",
    "summary": "The best outcome is the one with the greatest total sum of wellbeing across all individuals. Creating new happy people adds value, and larger populations with positive lives are better than smaller ones.",
    "key_intuition": "Every unit of wellbeing matters equally, regardless of who experiences it or when they come into existence."
  },
  {
    "id": "average-utilitarianism",
    "name": "Average Utilitarianism",
    "summary": "The best outcome is the one with the highest average wellbeing per person. Population size is irrelevant except insofar as it affects the mean welfare level.",
    "key_intuition": "What matters is how well lives go on average, not how many lives there are; quality over quantity."
  },
  {
    "id": "critical-level-positive",
    "name": "Critical Level Utilitarianism (Positive Threshold)",
    "summary": "We should maximize total wellbeing above a critical level that is set above zero. A new life only adds value if its wellbeing exceeds this positive threshold, not merely if it is worth living.",
    "key_intuition": "Lives that are barely worth living shouldn't count as adding significant value; there's a meaningful threshold above mere positive existence."
  },
  {
    "id": "critical-level-zero",
    "name": "Critical Level Utilitarianism (Zero Threshold)",
    "summary": "We should maximize total wellbeing above a critical level set at zero (neutrality). This is equivalent to standard total utilitarianism but framed within the critical level framework.",
    "key_intuition": "The natural threshold for a life adding value is that it be worth living at all."
  },
  {
    "id": "critical-level-negative",
    "name": "Critical Level Utilitarianism (Negative Threshold)",
    "summary": "We should maximize total wellbeing above a critical level set below zero. Even some lives with negative wellbeing can add value to the world if they exceed this negative threshold.",
    "key_intuition": "Existence itself has some intrinsic value, so even somewhat bad lives might contribute positively to overall value."
  },
  {
    "id": "person-affecting-necessitarianism",
    "name": "Person-Affecting Necessitarianism",
    "summary": "An outcome can only be better than another if it is better for someone who exists in both outcomes. Creating happy people cannot make an outcome better since those people don't exist in the alternative.",
    "key_intuition": "Value must be value for someone; we can't benefit people by bringing them into existence since there's no one who would otherwise be worse off."
  },
  {
    "id": "person-affecting-actualism",
    "name": "Person-Affecting Actualism",
    "summary": "An outcome is better if it is better for people who actually exist in that outcome. The welfare of merely possible people who don't come to exist has no moral weight.",
    "key_intuition": "Only actual people matter morally; we have no obligations to bring happy people into existence."
  },
  {
    "id": "narrow-person-affecting",
    "name": "Narrow Person-Affecting View",
    "summary": "An outcome is worse than another only if it is worse for someone. Combined with the view that existence cannot harm, this implies creating people with lives worth living is never wrong.",
    "key_intuition": "Wrongness requires a victim; if no one is made worse off, nothing wrong has occurred."
  },
  {
    "id": "variable-value-diminishing",
    "name": "Variable Value Theory (Diminishing)",
    "summary": "The marginal value of additional lives diminishes as population size increases. Early additions to a population contribute more value than later ones, even at the same welfare level.",
    "key_intuition": "There's something valuable about variety and the first instances of flourishing that isn't fully captured by simply counting welfare units."
  },
  {
    "id": "variable-value-geometric",
    "name": "Geometric Variable Value Theory",
    "summary": "Population value follows a geometric series where each additional person at a given welfare level contributes a fixed fraction of what the previous person contributed. Total value approaches an asymptotic limit.",
    "key_intuition": "The universe can only hold so much value from population size; at some point, more people add negligible value."
  },
  {
    "id": "negative-utilitarianism-strong",
    "name": "Strong Negative Utilitarianism",
    "summary": "Only suffering has intrinsic moral significance; happiness has no positive value. The goal is solely to minimize total suffering, and a world with no sentient beings would be optimal.",
    "key_intuition": "Suffering is the only thing that truly matters morally; happiness is merely the absence of suffering, not a positive good."
  },
  {
    "id": "negative-utilitarianism-weak",
    "name": "Weak Negative Utilitarianism",
    "summary": "Reducing suffering has lexical or significant priority over increasing happiness. We should first eliminate suffering before focusing on creating positive wellbeing.",
    "key_intuition": "Preventing suffering is more urgent than creating happiness; the badness of suffering outweighs the goodness of pleasure."
  },
  {
    "id": "asymmetric-procreation",
    "name": "Asymmetric View (Benatar-style)",
    "summary": "There is an asymmetry between the badness of suffering (which gives reasons against creating a life) and the goodness of happiness (which does not give reasons for creating a life). Absence of suffering is good even if no one benefits, but absence of happiness is not bad unless someone is deprived.",
    "key_intuition": "We have strong reasons to prevent suffering but no corresponding reasons to create happiness for non-existent beings."
  },
  {
    "id": "lexical-threshold-suffering",
    "name": "Lexical Threshold View (Suffering)",
    "summary": "No amount of positive wellbeing can compensate for sufficiently intense suffering. Once suffering crosses a threshold of severity, it cannot be outweighed by any quantity of happiness.",
    "key_intuition": "Some suffering is so terrible that it creates an incommensurable negative value; torture cannot be justified by enough mild pleasures."
  },
  {
    "id": "lexical-threshold-flourishing",
    "name": "Lexical Threshold View (Flourishing)",
    "summary": "Lives above a certain threshold of flourishing have lexically greater value than any number of lives below that threshold. A sufficient number of excellent lives is better than any number of merely good ones.",
    "key_intuition": "True human flourishing is qualitatively different from mere contentment; we should prioritize depth of wellbeing over breadth."
  },
  {
    "id": "maximin-population",
    "name": "Maximin Population Ethics",
    "summary": "The best population is the one that maximizes the welfare of the worst-off individual. Population size and total welfare are irrelevant except insofar as they affect the minimum welfare level.",
    "key_intuition": "Justice requires prioritizing the most vulnerable; a society is only as good as how it treats its worst-off members."
  },
  {
    "id": "leximin-population",
    "name": "Leximin Population Ethics",
    "summary": "First maximize the welfare of the worst-off; if tied, maximize the second-worst-off, and so on. This extends maximin to provide complete rankings when the worst-off are equally well off.",
    "key_intuition": "We should help the worst-off first, then the next worst-off, in lexical order of priority."
  },
  {
    "id": "prioritarianism-population",
    "name": "Prioritarian Population Ethics",
    "summary": "Wellbeing matters more the worse off a person is. We should maximize a sum of weighted wellbeing, where weights decrease as welfare increases, giving priority to improving bad lives.",
    "key_intuition": "Benefiting the worse off matters more than benefiting the better off, even if the benefit is the same size."
  },
  {
    "id": "sufficientarianism-population",
    "name": "Sufficientarian Population Ethics",
    "summary": "What matters most is ensuring everyone reaches a sufficient level of wellbeing. Below the threshold, improvements have great moral weight; above it, improvements matter much less or not at all.",
    "key_intuition": "There's a level of 'enough' that should be our primary moral target; once people have enough, further gains are less important."
  },
  {
    "id": "egalitarian-population",
    "name": "Egalitarian Population Ethics",
    "summary": "Equality of wellbeing has intrinsic value independent of total or average welfare. Populations with more equal distributions are better, all else being equal, even if this means less total welfare.",
    "key_intuition": "Inequality is intrinsically bad; a world where everyone is equally well off is better than one with the same average but unequal distribution."
  },
  {
    "id": "perfectionism-population",
    "name": "Perfectionist Population Ethics",
    "summary": "What matters is the realization of human excellences and objective goods, not subjective wellbeing. The best population is one that maximizes the achievement of perfection in art, knowledge, virtue, and other objective values.",
    "key_intuition": "Some achievements and forms of excellence are valuable regardless of whether they make people feel happy; Beethoven's symphonies matter beyond the pleasure they cause."
  },
  {
    "id": "virtue-based-population",
    "name": "Virtue-Based Population Ethics",
    "summary": "Population decisions should be guided by what a virtuous person would choose, considering virtues like compassion, justice, and practical wisdom. The focus is on the character of decision-makers rather than calculating outcomes.",
    "key_intuition": "Ethics is about being a good person, not maximizing metrics; a virtuous person would consider future generations with appropriate care and humility."
  },
  {
    "id": "contractualist-population",
    "name": "Contractualist Population Ethics",
    "summary": "Population policies are justified if they could not be reasonably rejected by any affected party. This often supports person-affecting intuitions since non-existent people cannot be parties to the contract.",
    "key_intuition": "Morality is about what we can justify to each other; we can't justify policies to people who will never exist."
  },
  {
    "id": "rights-based-population",
    "name": "Rights-Based Population Ethics",
    "summary": "Future people have rights that constrain our actions, but there is no right to be brought into existence. We must not violate the rights of those who will exist, but we have no duty to create people.",
    "key_intuition": "Rights provide side-constraints on action; we can wrong future people by harming them, but not by failing to create them."
  },
  {
    "id": "deontological-threshold",
    "name": "Deontological Threshold Population Ethics",
    "summary": "There are deontological constraints against creating lives below a certain welfare threshold (e.g., lives of suffering), but no positive duty to create good lives. Creating a life of suffering wrongs that person; failing to create a happy life wrongs no one.",
    "key_intuition": "We have a duty not to create people who will suffer, but no corresponding duty to create people who will flourish."
  },
  {
    "id": "hybrid-total-average",
    "name": "Hybrid Total-Average View",
    "summary": "Population value is a weighted combination of total and average wellbeing. Both the sum of welfare and how well lives go on average matter, with neither consideration completely dominating.",
    "key_intuition": "Both intuitions—that more happy people is better and that average quality matters—capture something important; we shouldn't fully sacrifice either."
  },
  {
    "id": "hybrid-total-prioritarian",
    "name": "Hybrid Total-Prioritarian View",
    "summary": "We should maximize a priority-weighted sum of wellbeing, where benefits to worse-off individuals count more, while also giving some weight to total welfare. This combines prioritarian and totalist intuitions.",
    "key_intuition": "We should care both about how much welfare exists and about its distribution, with special concern for those who are badly off."
  },
  {
    "id": "range-dependent-value",
    "name": "Range-Dependent Value Theory",
    "summary": "The value of a life depends on where it falls within the range of possible lives in that population. Lives are evaluated relative to the best and worst lives possible in their context.",
    "key_intuition": "What counts as a good life depends on what's possible; context matters for evaluating welfare."
  },
  {
    "id": "critical-range-theory",
    "name": "Critical Range Theory",
    "summary": "Instead of a single critical level, there is a range of levels such that lives within this range neither add nor subtract value. Only lives clearly above the range add value; only lives clearly below subtract value.",
    "key_intuition": "There's genuine vagueness or indeterminacy about which lives add value; we shouldn't pretend to precision we don't have."
  },
  {
    "id": "person-based-restricted",
    "name": "Restricted Person-Affecting View",
    "summary": "Person-affecting principles apply only to same-number choices; in different-number choices, we may appeal to impersonal considerations. This allows totalism for population size while maintaining person-affecting intuitions for distribution.",
    "key_intuition": "Person-affecting intuitions are strongest when comparing outcomes with the same people; different-number cases are genuinely different."
  },
  {
    "id": "comparative-fairness",
    "name": "Comparative Fairness View",
    "summary": "Population choices should be evaluated by what would be fair to all potentially affected parties, including merely possible people. Each possible person has a claim to existence that must be weighed fairly against others' claims.",
    "key_intuition": "Fairness requires considering the perspectives of all who might exist, not just those who actually will."
  },
  {
    "id": "expected-value-population",
    "name": "Expected Value Population Ethics",
    "summary": "Under uncertainty about population outcomes, we should maximize expected value according to our favored population axiology. Risk-neutrality applies to population ethics just as to other domains.",
    "key_intuition": "Uncertainty doesn't change the fundamental ethics; we should still aim at the best expected outcome."
  },
  {
    "id": "risk-averse-population",
    "name": "Risk-Averse Population Ethics",
    "summary": "We should be risk-averse regarding population outcomes, giving extra weight to avoiding bad outcomes even at the cost of expected value. Catastrophic population outcomes deserve special concern.",
    "key_intuition": "The stakes in population ethics are so high that we should be especially cautious about risking very bad outcomes."
  },
  {
    "id": "satisficing-population",
    "name": "Satisficing Population Ethics",
    "summary": "Rather than maximizing population value, we should aim for outcomes that are 'good enough.' Once a population reaches a satisfactory level of welfare and size, further optimization is not required.",
    "key_intuition": "Demanding constant maximization is unreasonable; morality should be achievable, and 'good enough' is genuinely good enough."
  },
  {
    "id": "pluralist-population",
    "name": "Pluralist Population Ethics",
    "summary": "Multiple irreducible values matter in population ethics: total welfare, average welfare, equality, sufficiency, and others. These values cannot be reduced to a single metric and may conflict.",
    "key_intuition": "Population ethics involves genuine value pluralism; no single principle captures everything that matters."
  },
  {
    "id": "time-relative-population",
    "name": "Time-Relative Population Ethics",
    "summary": "The value of creating a person depends on when they will exist, with some discount for temporal distance. Near-future people matter more than far-future people, though not purely due to probability of existence.",
    "key_intuition": "Temporal proximity has some moral relevance; we have stronger obligations to those who will exist soon."
  },
  {
    "id": "no-discount-population",
    "name": "Temporally Neutral Population Ethics",
    "summary": "The timing of a life has no intrinsic moral relevance. A person in the far future matters exactly as much as a person today, and pure time preference in population ethics is irrational.",
    "key_intuition": "When someone exists shouldn't affect how much they matter; temporal location is morally arbitrary like spatial location."
  },
  {
    "id": "identity-affecting-moderate",