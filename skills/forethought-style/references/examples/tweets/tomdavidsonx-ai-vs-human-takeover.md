# Thread from @TomDavidsonX

**Author:** Tom Davidson
**Date:** 2025-05-28
**URL:** https://x.com/TomDavidsonX/status/1927736989216026691

---

**1/9:** Which would be worse: AI taking over the world, or one human taking over?

I actually think it's plausible that a human would be worse, see ðŸ§µ

![](https://pbs.twimg.com/media/GsCyk2dbsAAMv_S.jpg)

**2/9:** I expect future AI to be more virtuous than humans.

They are today â€“ Claude is *way* more selfless and open-minded than most people.

And I expect we'll "reward" AIs for selfishness much less than evolution and lifetime learning "rewards" humans for selfishness.

**3/9:** But we shouldn't just compare the *expected* virtues of AI vs humans.

We should compare:
1. how virtuous is AI *conditional on AI having seized power*
2. how virtuous is a human *conditional on that human having seized power*

**4/9:** If AI takes over, our alignment efforts failed and AI may have completely alien values.

Or, AI may *share* humans goals (e.g. justice, flourishing) but be willing to take unethical actions to achieve them. E.g. AI seizing power to prevent WW3.

![](https://pbs.twimg.com/media/GsCynSDaAAEj5Fc.jpg)

**5/9:** If a human takes over, that makes them unusually likely to be narcissistic, machiavelli, psychopathic, and sadistic.

Some humans are really awful.

**6/9:** The above focuses on the *values* of AIs vs humans.

But, importantly, humans will likely be less competent.

Humans are more likely to start wars, allow terrorists to access WMDs, perpetuate moral catastrophes (e.g. factory farming), and mess up tricky issues (e.g. simulations, threats, acausal trade)

**7/9:** So, I think AI and human takeover would be similarly bad if they happened (in expectation).

I also think they are similarly likely to actually happen:

https://t.co/COZq40pGeI

**8/9:** Our recent paper analyses the risk of human takeover:
https://t.co/j20P0UOG5x

**9/9:** See more on the badness of human vs AI takeover in the full post:
https://t.co/75UQgWtlti
