# Thread from @LizkaVaintrob

**Author:** Lizka
**Date:** 2025-04-02
**URL:** https://x.com/LizkaVaintrob/status/1907546964855574816

---

**1/16:** AI could unlock an era of competent, enlightened governance. But if the US federal govt is too slow on AI adoption, it'll grow increasingly irrelevant.

In a new üìÉ I discuss the growing federal-private AI adoption gap, its implications for existential risk, & what we can do.

![](https://pbs.twimg.com/media/Gnjx7O0XQAAh4qZ.jpg)

**2/16:** Government integration of AI isn't just about employees using chatbots (although in many cases that'd already be an improvement!).

Picture automatic fraud recovery, advanced supply chain monitoring, constant cyber fixes, AI testing, secure oversight, great agreements, and more.

![](https://pbs.twimg.com/media/GnjzpSBXIAE0ra7.jpg)

**3/16:** Agencies have announced hundreds of AI "use cases", but the depth of government AI adoption is still trailing the private sector's.

Civilian agencies are even further behind ‚Äî in 2023 DOD spending accounted for 88-96% (!) of new federal AI contracts.

![](https://pbs.twimg.com/media/Gnjzvo1XcAAqaug.jpg)

**4/16:** Lack of talent, low funding, convoluted processes, bad data management, high security needs... slow the govt down.

Meanwhile, companies pull ahead, & the federal-private gap will likely keep growing; current frictions persist, compounding effects help leaders go even faster, etc

**5/16:** AI adoption could be key for effective govt responses to looming (complex, rapid) challenges.

Great monitoring to stop an engineered pandemic. Rapid analysis for de-escalating global conflicts. New tools for catching dangerous AI.

But *reactive* AI adoption would start too late

![](https://pbs.twimg.com/media/Gnjz6OTXkAAcF9a.jpg)

**6/16:** If the govt falls too far behind, it will lose influence to AI companies & other technologically dominant groups.

Tech companies could wield huge power, evading oversight & influencing govt decisions. A small govt group could rapidly pull ahead & illegitimately seize power.

**7/16:** Integrating AI in government will require care.

If adoption is reckless, government decisions & systems may be compromised, unsafe automation could trigger catastrophic failures, arms races will be exacerbated, & safety research timelines will be compressed.

![](https://pbs.twimg.com/media/Gnj0CqBW0AM7EVx.png)

**8/16:** Counterintuitively, slow adoption today likely *increases* total risk from govt AI integration:

Pressure to automate will keep building. A crisis or sudden change in priorities would eventually force a rapid scale-up (in esp risky times).

Making steady progress would be safer.

![](https://pbs.twimg.com/media/Gnj0RrGXcAA6ZX1.png)

**9/16:** Simple "pro-speed" or "pro-safety" positions encourage dumb choices; crippling use of AI for minor safeguards, blasting through safeguards for tiny gains.

We're not limited to a general "faster-safer" lever (no such lever exists!). Specific measures have different pros & cons.

**10/16:** Safety & speed aren't inherently at odds.

There are many win-win measures ‚Äî investing in technical talent, strengthening IT, streamlining procurement, etc.

(And many lose-lose measures! Clumsy/vague "safeguards" detract from others, poor incentives discourage learning, etc.)

![](https://pbs.twimg.com/media/Gnj08LCXUAAjOA3.jpg)

**11/16:** Overall, top recs include:
‚ú≥Ô∏è Invest in tech talent, modernize digital infrastructure, streamline procurement
üß∑ Grow funding for compliance w/ safeguards, build capacity for in-house testing, fund safety R&D
‚è© Develop AI tools for government settings, help key agencies adopt AI

![](https://pbs.twimg.com/media/Gnj1DlxWsAAoVEo.jpg)

**12/16:** Besides helping the government safely adopt AI, we need contingency plans for two risky scenarios:
üö´ State capacity collapse
üö® Rushed, late-stage government adoption of AI

![](https://pbs.twimg.com/media/Gnj1Wy5WAAALqmG.jpg)

**13/16:** üö´ Govt AI adoption might never ramp up; we should prepare for a possible "state collapse" scenario by:
- Building AI policy frameworks that work on the state or private level (per @deanwball), rather than the federal one
- Investing more in technical and non-policy interventions

**14/16:** üö® Shifting large institutions is hard. AI adoption could be lethargic until a crisis forces decisionmakers' hands.

Building external capacity ‚Äî like emergency "standby" teams of AI experts, or tools the govt can quickly and safely deploy ‚Äî could de-risk this scenario.

**15/16:** AI progress won't wait for institutional inertia. It'll soon introduce challenges for which the US govt's response will be critical. A widening AI adoption gap will leave the US govt behind & unable to act wisely.

Working towards safe *and* fast AI adoption is a key way to help.

![](https://pbs.twimg.com/media/Gnj2NngXgAAh05t.jpg)

**16/16:** For more, see the paper: https://t.co/cTpUS8ltVC
